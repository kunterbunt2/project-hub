# Index TTS Dockerfile Optimization

## Problem

The original Dockerfile was based on `python:3.11-slim` and had to install:

- PyTorch (~2.2GB download)
- CUDA toolkit
- cuDNN
- Build tools

This caused extremely long build times (10+ minutes just for PyTorch download).

## Solution

Switched to NVIDIA's official PyTorch image: `nvcr.io/nvidia/pytorch:24.09-py3`

### What's Included in NVIDIA PyTorch Image

- ‚úÖ Python 3.11
- ‚úÖ PyTorch 2.4+ with CUDA 12.6 support
- ‚úÖ CUDA toolkit (pre-configured)
- ‚úÖ cuDNN (pre-configured)
- ‚úÖ NumPy, SciPy (already installed)
- ‚úÖ Optimized for NVIDIA GPUs
- ‚úÖ All build tools

## Changes Made

### 1. Updated Dockerfile

**Before:**

```dockerfile
FROM python:3.11-slim

# Install build tools
RUN apt-get update && apt-get install -y \
    git \
    git-lfs \
    build-essential \
    libsndfile1 \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Install PyTorch with CUDA (2.2GB+ download)
RUN pip install --no-cache-dir \
    torch==2.1.2 \
    torchvision==0.16.2 \
    torchaudio==2.1.2 \
    --index-url https://download.pytorch.org/whl/cu121
```

**After:**

```dockerfile
FROM nvcr.io/nvidia/pytorch:24.09-py3

# Install only what's needed
RUN apt-get update && apt-get install -y \
    git \
    git-lfs \
    libsndfile1 \
    curl \
    && rm -rf /var/lib/apt/lists/*
```

### 2. Updated requirements.txt

**Removed (already in base image):**

- ‚ùå `numpy==1.26.3` - Already in PyTorch image
- ‚ùå `scipy==1.12.0` - Already in PyTorch image
- ‚ùå PyTorch installation notes - No longer needed

**Kept (needed for Index TTS):**

- ‚úÖ FastAPI and server dependencies
- ‚úÖ Audio processing (soundfile, librosa)
- ‚úÖ Hugging Face tools
- ‚úÖ Index TTS specific dependencies

### 3. Benefits

| Aspect                      | Before (python:3.11-slim) | After (nvidia/pytorch:24.09-py3) |
|-----------------------------|---------------------------|----------------------------------|
| **Base Image Size**         | ~150MB                    | ~8GB (but includes everything)   |
| **Build Time**              | 10-15 minutes             | 2-3 minutes                      |
| **PyTorch Download**        | Yes (2.2GB)               | No (included)                    |
| **CUDA Setup**              | Manual                    | Pre-configured                   |
| **GPU Optimization**        | Standard                  | NVIDIA-optimized                 |
| **Dependencies to Install** | Many                      | Few                              |

### 4. PyTorch Version Upgrade

- **Before:** PyTorch 2.1.2 + CUDA 12.1
- **After:** PyTorch 2.4+ + CUDA 12.6 (from NVIDIA image)
- **Compatibility:** Index TTS works with PyTorch 2.x, so this is fine

## How to Rebuild

```cmd
# Stop the old container
.\index-tts-helper.bat stop

# Remove old container and image (optional, but recommended)
docker rm index-tts
docker rmi index-tts

# Build with new Dockerfile (much faster now!)
.\index-tts-helper.bat build

# Start the container
.\index-tts-helper.bat start

# Check logs
.\index-tts-helper.bat logs
```

## Expected Build Time Comparison

### Before (python:3.11-slim base)

```
[ 1/18] FROM python:3.11-slim           : 30s
[ 6/18] Install PyTorch + CUDA          : 300s+ (5+ minutes)
[ 8/18] Clone Index TTS                 : 60s
[10/18] Install Index TTS dependencies  : 120s
Total: ~10-15 minutes
```

### After (nvidia/pytorch:24.09-py3 base)

```
[ 1/15] FROM nvidia/pytorch:24.09-py3   : 60s (cached after first pull)
[ 5/15] Clone Index TTS                 : 60s
[ 7/15] Install Index TTS dependencies  : 60s
Total: ~2-3 minutes (first build)
       ~1-2 minutes (subsequent builds with cache)
```

## Verification

After rebuilding, verify the setup:

```bash
# Check container is running
docker ps | grep index-tts

# Check PyTorch version
docker exec index-tts python -c "import torch; print(f'PyTorch: {torch.__version__}')"

# Check CUDA availability
docker exec index-tts python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# Check server is responding
curl http://localhost:5124/health
```

Expected output:

```json
{
  "status": "healthy",
  "model_loaded": true,
  "device": "cuda",
  "cuda_available": true
}
```

## Troubleshooting

### Issue: "No CUDA-capable device is detected"

**Solution:** Ensure Docker Desktop has GPU support enabled:

1. Docker Desktop ‚Üí Settings ‚Üí Resources ‚Üí WSL Integration
2. Enable GPU support for your WSL distribution

### Issue: Build fails at Index TTS installation

**Solution:** The NVIDIA image uses a different Python environment. If issues occur:

```dockerfile
# Try installing Index TTS with --no-deps and install deps separately
RUN pip install --no-cache-dir --no-deps -e /opt/index-tts
```

### Issue: "python-multipart not found"

**Solution:** Already fixed in requirements.txt. Rebuild the container.

## Files Changed

- ‚úÖ `docker/index-tts/Dockerfile` - Use NVIDIA PyTorch base image
- ‚úÖ `docker/index-tts/requirements.txt` - Removed redundant dependencies

## Next Steps

1. Rebuild the container with the optimized Dockerfile
2. Test voice reference upload/management
3. Generate test speech to verify everything works

The build should now be **5-10x faster**! üöÄ

