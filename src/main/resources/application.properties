#
#
# Copyright (C) 2025-2025 Abdalla Bushnaq
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#
#
spring.profiles.default=h2
#enable=h2 console available at http://localhost:8080/h2-console
#JDBC=URL: jdbc:h2:testdb
#User=Name: sa
#Password=password
server.port=8080
projecthub.api.base-url=http://localhost:8080/api
spring.datasource.url=jdbc:h2:file:./db
spring.datasource.driverClassName=org.h2.Driver
spring.datasource.username=sa
spring.datasource.password=password
spring.jpa.hibernate.ddl-auto=update
#spring.h2.console.enabled=true
#spring.h2.console.path=/h2-console
#spring.jpa.show-sql=true
spring.jpa.properties.hibernate.format_sql=true
springdoc.api-docs.path=/v3/api-docs
#
#Base path to be used by Spring Data REST to expose repository resources
#only needed if we include spring-boot-starter-data-rest
#spring.data.rest.base-path=/api
#
springdoc.swagger-ui.path=/swagger-ui.html
#springdoc.packages-to-scan=de.bushnaq.abdalla.projecthub.rest.controller
springdoc.swagger-ui.defaultModelsExpandDepth=-1
springdoc.default-produces-media-type=application/json
#
# VAADIN
#
# Launch the default browser when starting the application in development mode
vaadin.launch-browser=true
vaadin.allowed-packages=com.vaadin,org.vaadin,com.flowingcode,de.bushnaq.abdalla
#
# Spring AI / Ollama Configuration for offline LLM support
#
# Llama 3.2 Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.enabled=false
spring.ai.ollama.chat.options.model=llama3.2:3b-instruct-fp16
spring.ai.ollama.chat.options.temperature=0.8
spring.ai.ollama.chat.options.top-k=10
spring.ai.ollama.chat.options.top-p=0.9
# Mistral 7B Configuration
spring.ai.mistral.base-url=http://localhost:11434
spring.ai.mistral.chat.enabled=true
spring.ai.mistral.chat.options.model=mistral:7b
spring.ai.mistral.chat.options.temperature=0.8
spring.ai.mistral.chat.options.top-k=10
spring.ai.mistral.chat.options.top-p=0.9
#
# To improve the performance during development.
# For more information https://vaadin.com/docs/latest/flow/integrations/spring/configuration#special-configuration-parameters
