services:
  index-tts:
    build:
      context: ./docker/index-tts
      dockerfile: Dockerfile
    container_name: index-tts
    ports:
      - "5124:5000"
    volumes:
      - ./docker/index-tts/checkpoints:/opt/index-tts/checkpoints
      - index-tts-cache:/cache
      - ./docker/index-tts/server.py:/app/server.py:rw
    environment:
      - MODEL_PATH=/opt/index-tts/checkpoints
      - CACHE_PATH=/cache
      - HOST=0.0.0.0
      - PORT=5000
      - DEVICE=cuda  # Use 'cpu' for CPU-only systems
      - HF_HUB_CACHE=/cache
      - HF_ENDPOINT=https://hf-mirror.com
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: unless-stopped

volumes:
  index-tts-cache:
    driver: local

